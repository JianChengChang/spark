{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638855a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "     |████████████████████████████████| 9.5 MB 1.2 MB/s            \n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "     |████████████████████████████████| 503 kB 1.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/david/pythonenv/jupyter/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "     |████████████████████████████████| 14.8 MB 1.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/david/pythonenv/jupyter/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.19.5 pandas-1.1.5 pytz-2021.3\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397128b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d873ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['tom', 10], ['nick', 15], ['juli', 14]]\n",
    "df = pd.DataFrame(data, columns = ['name','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65207482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/pythonenv/jupyter/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74391fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bfbab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "| tom| 10|\n",
      "|nick| 15|\n",
      "|juli| 14|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73a7bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0976fe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'bigint')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c60730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+\n",
      "|name|age|new_col|\n",
      "+----+---+-------+\n",
      "| tom| 10|      1|\n",
      "|nick| 15|      1|\n",
      "|juli| 14|      1|\n",
      "+----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "sdf = sdf.withColumn('new_col', lit(1))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9fe708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+--------+\n",
      "|name|age|new_col|new_col2|\n",
      "+----+---+-------+--------+\n",
      "| tom| 10|      1|      11|\n",
      "|nick| 15|      1|      16|\n",
      "|juli| 14|      1|      15|\n",
      "+----+---+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = sdf.withColumn('new_col2', sdf.age+1)\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e22182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+--------+\n",
      "|name|age|new_col|new_col2|\n",
      "+----+---+-------+--------+\n",
      "|nick| 15|      1|      16|\n",
      "+----+---+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.filter(sdf.name=='nick').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea6a366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='nick', age=15, new_col=1, new_col2=16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.filter(sdf.name=='nick').collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3ba0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.filter(sdf.name=='nick').collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c475ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['tom', 10], ['nick', 15], ['juli', 14],['nick',10],['david',15],['tom',40]]\n",
    "df = pd.DataFrame(data, columns = ['name','age'])\n",
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4409b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|david|\n",
      "| juli|\n",
      "| nick|\n",
      "|  tom|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.select('name').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c01042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e1dc57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| name|avg(age)|\n",
      "+-----+--------+\n",
      "|david|    15.0|\n",
      "| juli|    14.0|\n",
      "| nick|    12.5|\n",
      "|  tom|    25.0|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.groupby('name').agg(mean('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['tom', 160, ['nick', 80], ['juli', 70],['nick',10],['david',90],['tom',40]]\n",
    "df = pd.DataFrame(data, columns = ['name','age'])\n",
    "sdf = spark.createDataFrame(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
